# Project Specification Document

## Project basics

This project is part of the Bachelor's Programme in Computer Science at Helsinki University. The application is implemented in Python, and documentation is done in English. I am able to complete peer reviews for projects created with Python, CSS, HTML, JavaScript, SQL, and R. 

## Application Purpose

The purpose of this project is to practice implemention of more advanced data structures and algorithms from scratch. **Verbum Reprehendo**, a spell checker for the most common English words, takes advantage of trie, a digital tree data structure, and Damerau-Levehnstein distance in its implementation. 

**Verbum Reprehendo** is a simple command line spell checker, where the user can input a sentence, and the application indicates which words are correctly written. For the misspelled ones, the application suggests alternative correctly written words. 

## Approach

**Problem to be solved** in the application is to be able to recognize whether a word typed by the user is a valid English word, and if it is not, what the correctly spelled word could be. 

To be able to do this, the first item needed is a correctly spelled list of **English language words**. Princeton University's [WordNet](https://wordnet.princeton.edu/), which consists of ~150,000 commonly used English words (nouns, verbs, adjectives and adverbs), is used as a basis for the application's data. This application is developed complying with the [WordNet 3.0 license](https://wordnet.princeton.edu/license-and-commercial-use) that maintains the copyright with the Princeton University. 

To be able to use the dictionary efficiently, words will be saved in the **trie structure**, which is a digital tree structure for locating specific keys from within a set. Keys are strings that are linked between nodes defined by individual charaters. To access a key, the trie is traversed depth first. Trie structure is used in this application because is allows fairly efficient searching for e.g. spell checkers. Time complexity for search, insertion and deletion operations as well as space is O(n). (Source: [Wikipedia: Trie, 2022](https://en.wikipedia.org/wiki/Trie)). Further sources to understand the trie structure include articles by the key inventors of the trie structure, [de la Briandais (1959)](https://dl.acm.org/doi/pdf/10.1145/1457838.1457895) and [Fredkin (1960)](https://dl.acm.org/doi/10.1145/367390.367400), and examples of implementation from e.g. [Tutorialspoint (2022)](https://www.tutorialspoint.com/implement-trie-prefix-tree-in-python#).

Once the user types in text in the command line and asks to check the spelling, the application will check whether the word is English by comparing it to the WordNet's dictionary. As mentioned, the operations of the trie structure will be used for this. In case the word is not available in the dictionary, the application will generate **alternative words** of the misspelled word with a Damerau-Levehnstein distance of one. Damerau-Levenhstein distance is a string metric for measuring the distance between two sequences and it tells the number of operations (insertaions, deletions, substitutions of a single character, or transposition of two adjacent characters) needed to change one word into another. This metric is used, because it was originally developed especially to be used in spell checkers. (Source: [Wikipedia: Damerau-Levenhstein distance, 2022](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)). 

In the first phase, the simpler verion of Damerau-Levehnstein, i.e. the optimal string alignment distance, that allows for only one change in the word, is used, since it is significantly easier to implement, and based on the original article, one error corresponds to 80% of the cases.  Time complexity for the Wagner-Fischer algorithm to calcute the Damerau-Levenhstein distance is O(mn), though it can be made more efficient (Source: [Wikipedia: Wagner-Fischer algorithm, 2022](https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm)). Further sources to understand the algorithm include e.g. the original article by [Damerau (1964)](https://dl.acm.org/doi/abs/10.1145/363958.363994), and examples of implemention by [Jensen (2022)](https://www.lemoda.net/text-fuzzy/damerau-levenshtein/index.html).

Once the alternative words have been developed, the user will be shown either 
* The full list of the alternative **correctly spelled** words generated. This requires selecting from the words generated by the Wagner-Fischer algorithm only the ones that are in the dictionary with the trie structure search operation.

    or

* One or a few words that are most likely the correct word that the user is trying to type. In this case, data on the frequency of different English words in the English corpus is needed. This data is available from the [British National Corpus](https://varieng.helsinki.fi/CoRD/corpora/BNC/index.html). Based on the frequency of the words in the corpus, the probabilities of the different words can be calculated, and the most likely word(s) can be shown for the user, following examples from [Roos (2021)](https://materiaalit.github.io/intro-to-ai/part3/) or [Norvig (2016)](http://norvig.com/spell-correct.html).

    and

* An option to ignore the suggestions and to leave the word as is.

Based on these alternatives, the user can select the correct word to be used in their text, and in the end the text will be fully corrected.

## Ideas for further development
* Completeness of the dictionary: Princeton University's Wordnet does not incorporate English stop words (such as and, a, of). It would be important to add these to the list of words used in the application.
* Alternative words, improvement 1: Full Damerau-Levehnstein, allowing also for transposition for characters in a string, may be implemented. 
* Alternative words, improvement 2: The calculation of the Wagner-Fischer algorithm can be made more time efficient with certain optimizations.
* Alternative words, improvement 3: User can add a word to the dictionary.
* UI: Graphical UI for writing and editing the sentences would improve the visuals of the application.